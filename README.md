# Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in Multiparty Dialogues

In this paper, we build a context‑aware speaker‑identification model that leverages fuzzy fingerprints for the Text‑Based Speaker Identification Task.
We share the splits used in our work for future research. [[soon]]()

## Citation
If you find this paper useful in your work, please cite the following paper:
```
@inproceedings{...}

@article{...},
}
```

**Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in Multiparty Dialogues**. [[soon]]()

### Abstract
> Speaker identification using voice recordings leverages unique acoustic features, but this approach fails when only textual data is available. Few approaches have attempted to tackle the problem of identifying speakers solely from text, and the existing ones have primarily relied on traditional methods. In this work, we explore the use of fuzzy fingerprints from large pre-trained models to improve text-based speaker identification. We integrate speaker-specific tokens and context-aware modeling, demonstrating that conversational context significantly boosts accuracy, reaching 70.6% on the Friends dataset and 67.7% on the Big Bang Theory dataset. Additionally, we show that fuzzy fingerprints can approximate full fine-tuning performance with fewer hidden units, offering improved interpretability. Finally, we analyze ambiguous utterances and propose a mechanism to detect speaker-agnostic lines. Our findings highlight key challenges and provide insights for future improvements in text-based speaker identification.
